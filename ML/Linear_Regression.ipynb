{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce9afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde57a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaler(X,epsilon = 1e-10 , train= True, train_mean= None, train_std = None):\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # scaling train data and saving mean and std for test data\n",
    "    if train == True:\n",
    "        mean = X.mean(axis=0, keepdims=True)\n",
    "        std = X.std(axis=0, keepdims=True)\n",
    "        out = (X- mean)/(std + epsilon)\n",
    "        return out, mean , std\n",
    "    # scaling test data with train data mean & std \n",
    "    elif train == False :\n",
    "        out = (X- train_mean)/(train_std+epsilon)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604410b0",
   "metadata": {},
   "source": [
    "\n",
    "# first way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d090fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_gradient_descent():\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.loss = None\n",
    "        self.loss_fn = None\n",
    "        self.optimizer = None\n",
    "    \n",
    "    def calculate_loss(self,y, y_hat,func = 'mse'):\n",
    "        if func == 'mse':\n",
    "            return np.mean((y-y_hat)**2)\n",
    "        if func == 'mae':\n",
    "            return np.mean(np.abs(y-y_hat))\n",
    "    \n",
    "    def init_weights(self, X):\n",
    "        return np.zeros((X.shape[1], 1))\n",
    "    \n",
    "    def fit(self, X, y, epochs ,LR):\n",
    "        row_X = X\n",
    "        X = np.concatenate((row_X, np.ones((X.shape[0], 1))), axis = 1)\n",
    "        self.w = self.init_weights(X)\n",
    "        self.loss = []\n",
    "        for epoch in range(epochs):\n",
    "            y_hat = X @ self.w\n",
    "            self.w -= 2 * LR * (X.T @ (y_hat - y)) / X.shape[0]\n",
    "            self.loss.append(self.calculate_loss(y, y_hat))\n",
    "            if epoch%20 ==0 or epoch == epochs -1:\n",
    "                print(f\"epoch {epoch} | loss : {self.calculate_loss(y, y_hat)}\")\n",
    "            if epoch > 1 and abs(self.loss[-2] - self.loss[-1]) < 1e-6:\n",
    "                break\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1)\n",
    "        return X @ self.w\n",
    "    \n",
    "    def test_model(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        print(\"loss:\", self.calculate_loss(y, y_hat))\n",
    "\n",
    "        r2 = 1 - np.sum((y - y_hat)**2) / np.sum((y - y.mean())**2)\n",
    "        print(\"RÂ² score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33900d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(-10, 10 , 1000)\n",
    "x2 = np.linspace(-100, 100, 1000)\n",
    "X = np.concatenate((x1.reshape(-1, 1), x2.reshape(-1, 1)), axis = 1)\n",
    "\n",
    "y = X @ np.array([[10], [5.5]])+ 3 + np.random.normal(0, 1, (1000,1))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, shuffle = True, train_size = 0.8)\n",
    "x_train, mean, std = data_scaler(x_train, train =True)\n",
    "x_test = data_scaler(x_test, train=False, train_mean=mean, train_std=std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fadf176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Regression_gradient_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "774907f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss : 138510.01245570026\n",
      "epoch 20 | loss : 27062.31423848512\n",
      "epoch 40 | loss : 5288.494604603332\n",
      "epoch 60 | loss : 1034.3100383445747\n",
      "epoch 80 | loss : 203.04498670192316\n",
      "epoch 100 | loss : 40.58091732781094\n",
      "epoch 120 | loss : 8.812851379349006\n",
      "epoch 140 | loss : 2.593928674159772\n",
      "epoch 160 | loss : 1.3733824371525136\n",
      "epoch 180 | loss : 1.1324423459528845\n",
      "epoch 200 | loss : 1.0842624977225208\n",
      "epoch 220 | loss : 1.0743558120404986\n",
      "epoch 240 | loss : 1.072200216505678\n",
      "epoch 260 | loss : 1.071680958704765\n",
      "epoch 280 | loss : 1.0715357778860732\n",
      "epoch 300 | loss : 1.071487921573678\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, 1000, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967617f6",
   "metadata": {},
   "source": [
    "# secound way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27815ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression_closed_form():\n",
    "    pass #for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
